ğŸ“š RAG YouTuber Assistant
En AI-driven RAG-applikation (Retrieval Augmented Generation) som svarar pÃ¥ frÃ¥gor om data engineering-innehÃ¥ll baserat pÃ¥ transkriptioner frÃ¥n YouTube-videor.
Projektet bestÃ¥r av:

en Streamlit-frontend
en FastAPI-backend
en vektordatabas (LanceDB)
Gemini embeddings
Serverless deployment i Azure Functions


ğŸš€ Ã–versikt
AnvÃ¤ndaren kan stÃ¤lla frÃ¥gor som:
â€œWhich SQL video should I watch?â€
Systemet:
sÃ¶ker relevanta dokument i vektordatabasen
hÃ¤mtar rÃ¤tt kontext
genererar ett svar med hjÃ¤lp av Gemini AI
Detta sÃ¤kerstÃ¤ller att svaren baseras pÃ¥ faktiskt innehÃ¥ll, inte hallucinationer.


ğŸ§  Vad Ã¤r RAG?
RAG (Retrieval Augmented Generation) innebÃ¤r att:
AI-modellen inte gissar
den svarar endast utifrÃ¥n lagrad data
I detta projekt:
YouTube-transkriptioner â†’ embeddings
embeddings â†’ lagras i LanceDB
frÃ¥gor â†’ matchas semantiskt
svar â†’ genereras med Gemini


ğŸ—ï¸ Arkitektur
[ Streamlit Frontend ]
          |
          v
[ Azure Function (FastAPI) ]
          |
          v
[ LanceDB Vector Store ]
          |
          v
[ Gemini Embeddings & LLM ]
ğŸ§° Tech Stack
Del	Teknik
Frontend	Streamlit
Backend	FastAPI
AI	Gemini (Google Generative AI)
Vector DB	LanceDB
Serverless	Azure Functions (Flex Consumption)
Deployment	Azure
SprÃ¥k	Python 3.12

ğŸ“ Projektstruktur
.
â”œâ”€â”€ api.py                   # FastAPI entry point for Azure Functions
â”œâ”€â”€ function_app.py          # Azure Functions main configuration
â”œâ”€â”€ ingestion.py             # Script to process and load transcripts into LanceDB
â”œâ”€â”€ requirements.txt         # Project dependencies
â”œâ”€â”€ backend/
â”‚   â”œâ”€â”€ rag.py               # Core RAG logic (Gemini + Vector Search)
â”‚   â”œâ”€â”€ data_models.py       # Pydantic models for API requests/responses
â”‚   â””â”€â”€ constants.py         # Configuration constants and prompts
â”œâ”€â”€ frontend/
â”‚   â””â”€â”€ app.py               # Streamlit UI code
â”œâ”€â”€ data/
â”‚   â””â”€â”€ transcripts/         # Raw markdown files containing YouTube transcripts
â”œâ”€â”€ knowledge_base/          # Vector database storage (LanceDB)
â”‚   â””â”€â”€ articles.lance/      # Indexed data used for retrieval
â”œâ”€â”€ assets/                  # Images and static files for the UI/README
â””â”€â”€ explorations/            # Jupyter notebooks for testing and prototyping


âš™ï¸ KÃ¶ra projektet lokalt
1. Aktivera miljÃ¶
source venv/bin/activate
1. Indexera data
uv run ingestion.py
1. Starta backend
uvicorn api:app --reload
1. Starta frontend
uv run streamlit run frontend/app.py

â˜ï¸ Deployment i Azure
Backend Ã¤r deployad som Azure Function App
API-nyckel sÃ¤tts via Application Settings
Serverless â†’ skalar automatiskt
ğŸ”— Publikt API:
https://rag-youtube-rag.azurewebsites.net/rag/query
ğŸ”— API-dokumentation:
https://rag-youtube-rag.azurewebsites.net/docs


ğŸ§ª Exempel pÃ¥ frÃ¥ga
POST /rag/query
{
  "prompt": "Which SQL video do you recommend?"
}

âœï¸ Reflektion
Det mest utmanande var att:
integrera FastAPI med Azure Functions
hantera miljÃ¶variabler i molnet
Projektet gav djup fÃ¶rstÃ¥else fÃ¶r:
RAG-arkitektur
serverless deployment
AI-system i produktion


ğŸ‘¤ FÃ¶rfattare
Abdulrahman Fahmi
Data Engineering Student


# ingest data
uv run ingestion.py

# start backend
uvicorn api:app --reload

# start frontend
uv run streamlit run frontend/app.py

How It Works

PDFs from Wikipedia are converted to text
Text is embedded and stored in LanceDB
A question triggers vector search
The model answers using only retrieved content
The source file is shown
If the answer is not in the data, the system says so.

Author

Abdulrahman Fahmi
Data Engineering Student
